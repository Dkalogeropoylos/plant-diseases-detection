# -*- coding: utf-8 -*-
"""erg

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V3vNF6k-rNVGn5kHscmnSTfe2jVj7zwE
"""

from google.colab import drive
drive.mount('/content/gdrive')

!unzip /content/gdrive/MyDrive/ergasiam.zip -d correctfile

import random
import os
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import LogisticRegression
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, save_model, load_model
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
import matplotlib.pyplot as plt
import cv2
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as snsfrom tensorflow.keras.applications import DenseNet121
import numpy as np
from sklearn.calibration import CalibratedClassifierCV
from sklearn.isotonic import IsotonicRegression
from sklearn.metrics import accuracy_score, log_loss

pip install tensorflow-addons

pip install tensorflow-addons

"""PLOT IMAGES"""

def rescale_and_plot_images(image_files, class_name):
    for idx, img_path in enumerate(image_files):
        plt.subplot(3, 3, idx + 1)
        img = plt.imread(img_path)
        plt.imshow(img, cmap='gray')
        plt.title(class_name)

def plot_images(path, class_name):
    image_paths = []
    class_name_path = os.path.join(path, class_name)
    image_paths = [os.path.join(class_name_path, img_png) for img_png in random.sample(os.listdir(class_name_path), 3)]

    plt.figure(figsize=(10, 25))
    rescale_and_plot_images(image_paths, class_name)


plot_images(train_dir, 'Healthy')
plot_images(train_dir, 'Rust')
plot_images(train_dir, 'Powdery')

"""AUGMENTATIONS"""

np.random.seed(42)
tf.random.set_seed(42)

train_dir = '/content/correctfile/Train/Train'
valid_dir = '/content/correctfile/Validation/Validation'
test_dir = '/content/correctfile/Test/Test'


target_size = (224, 224)
batch_size = 31


train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)


valid_test_datagen = ImageDataGenerator(rescale=1.0/255.0)


train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

valid_generator = valid_test_datagen.flow_from_directory(
    valid_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

test_generator = valid_test_datagen.flow_from_directory(
    test_dir,
    target_size=target_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

"""VGG16  Freeze all layers except the last two


"""

pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers[:-2]:
    layer.trainable = False


model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""VGG16  Unfreeze all layers"""

import tensorflow as tf

pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers:
    layer.trainable = True

model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""VGG16 Freeze all layers except the last one"""

pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers[:-1]:
    layer.trainable = False

# Create your own custom model
model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""InceptionV3 Unfreeze all layers"""

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in base_model.layers:
    layer.trainable = True


x = base_model.output
x = GlobalAveragePooling2D()(x)


x = Dense(1024, activation='relu')(x)


output = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

"""InceptionV3 Freeze all layers except the last one



"""

pretrained_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers[:-1]:
    layer.trainable = False

# Create your own custom model
model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""InceptionV3 Freeze all layers except the last two

"""

pretrained_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers[:-2]:
    layer.trainable = False

# Create your own custom model
model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""InceptionV3 Freeze all layers except the last one

"""

pretrained_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers[:-1]:
    layer.trainable = False


model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""InceptionV3 UnFreeze all layers"""

pretrained_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in pretrained_model.layers:
    layer.trainable = True

model1 = tf.keras.models.Sequential()
model1.add(pretrained_model)
model1.add(tf.keras.layers.Flatten())
model1.add(tf.keras.layers.Dense(256, activation='relu'))
model1.add(tf.keras.layers.Dropout(0.5))
model1.add(tf.keras.layers.Dense(3, activation='softmax'))

"""new_model"""

img_width, img_height = 224,224
NAME = 'Model3_CNN_{}'.format(datetime.datetime.now().strftime("%d.%m.%Y-%H_%M"))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

input_shape = (224, 224, 3)

model = Sequential()


model.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))


model.add(Dense(32, activation='relu'))
model.add(Dropout(0.5))  # Dropout layer for regularization

model.add(Dense(3, activation='softmax'))

model.summary()

"""DENSENET121 UnFreeze all layers


"""

base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in base_model.layers[:-2]:
    layer.trainable = False


x = base_model.output
x = GlobalAveragePooling2D()(x)


x = Dense(1024, activation='relu')(x)


output = Dense(3, activation='softmax')(x)

model5 = Model(inputs=base_model.input, outputs=output)


model5.summary()

"""DENSENET121-Freeze all layers except the last one"""

base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))


for layer in base_model.layers[:-1]:
    layer.trainable = False


x = base_model.output
x = GlobalAveragePooling2D()(x)


x = Dense(1024, activation='relu')(x)


output = Dense(3, activation='softmax')(x)

model5 = Model(inputs=base_model.input, outputs=output)


model5.summary()

"""FIT THE MODELS WITH THE SAME WAY"""

import tensorflow_addons as tfa
from tensorflow.keras.callbacks import EarlyStopping

num_epochs = 40

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tfa.metrics.F1Score(num_classes=3, average='weighted')])

# Define the early stopping callback
early_stop = EarlyStopping(monitor='val_f1_score', patience=4, mode='max')

# Train the model with early stopping
H = model.fit(train_generator,
    steps_per_epoch=42,
    epochs=num_epochs,
    validation_data=valid_generator,
    validation_steps=round(valid_generator.samples / batch_size),
    callbacks=[early_stop]
)

"""PLOT THE LOSS IN TRAINING AND VALIDATION"""

plt.plot(H.history['loss'], color='blue', label='Train')
plt.plot(H.history['val_loss'], color='red', label='validation')

plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.savefig('./model1_train_test_loss.jpg', dpi=300)
plt.show()

"""PLOT THE ACCURACY IN TRAINING AND VALIDATION"""

train_color = 'red'
test_color = 'blue'

plt.plot(H.history['f1_score'], color=test_color, label='Train')

plt.plot(H.history['val_f1_score'], color=train_color, label='Validation')

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='lower right')


plt.grid(True)
plt.tight_layout()


plt.savefig('./model1_train_test_accuracy.jpg', dpi=300)
plt.show()

"""CLASSIFICATION REPORT AND CONFUSION MATRIX"""

class_names = list(test_generator.class_indices.keys())



num_test_samples = len(test_generator)


true_labels = []
predicted_labels = []


for i in range(num_test_samples):
    batch_images, batch_labels = test_generator[i]
    true_labels.extend(np.argmax(batch_labels, axis=1))


    batch_predictions = model.predict(batch_images)
    predicted_labels.extend(np.argmax(batch_predictions, axis=1))

true_labels = np.array(true_labels)
predicted_labels = np.array(predicted_labels)


report = classification_report(true_labels, predicted_labels, target_names=class_names)


cm = confusion_matrix(true_labels, predicted_labels)


print("Classification Report:")
print(report)
print()


print("Confusion Matrix:")
print(cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""CALIBRATION WITH TEMPERATURE SCALING (T=1)"""

import numpy as np


validation_pred_probs = model.predict(valid_generator)


temperature = 1.0


scaled_pred_probs = validation_pred_probs ** (1.0 / temperature)
normalized_pred_probs = scaled_pred_probs / np.sum(scaled_pred_probs, axis=1, keepdims=True)


test_pred_probs = model.predict(test_generator)
scaled_test_pred_probs = test_pred_probs ** (1.0 / temperature)
normalized_test_pred_probs = scaled_test_pred_probs / np.sum(scaled_test_pred_probs, axis=1, keepdims=True)


test_true_labels = test_generator.classes
test_loss_temperature = log_loss(test_true_labels, normalized_test_pred_probs)
test_accuracy_temperature = accuracy_score(test_true_labels, np.argmax(normalized_test_pred_probs, axis=1))

print('Test Loss (Temperature Calibration):', test_loss_temperature)
print('Test Accuracy (Temperature Calibration):', test_accuracy_temperature)

"""ISOTONIC CALIBRATION"""

validation_pred_probs = model.predict(valid_generator)
validation_true_labels = valid_generator.classes

isotonic_regressor = IsotonicRegression(out_of_bounds='clip')
isotonic_regressor.fit(validation_pred_probs[:, 0], validation_true_labels)

calibrated_test_probs_isotonic = np.column_stack((
    isotonic_regressor.predict(test_generator)[:, 0],
    isotonic_regressor.predict(test_generator)[:, 1],
    isotonic_regressor.predict(test_generator)[:, 2]
))

test_true_labels = test_generator.classes

test_loss_isotonic = log_loss(test_true_labels, calibrated_test_probs_isotonic)
test_accuracy_isotonic = accuracy_score(test_true_labels, np.argmax(calibrated_test_probs_isotonic, axis=1))

print('Test Loss (Isotonic Calibration):', test_loss_isotonic)
print('Test Accuracy (Isotonic Calibration):', test_accuracy_isotonic)